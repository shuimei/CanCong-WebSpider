#!/usr/bin/env python3
"""
å¤šè¿›ç¨‹è°ƒåº¦å™¨æµ‹è¯•è„šæœ¬
ç®€å•æµ‹è¯•å¤šè¿›ç¨‹åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from scripts.spider_scheduler import SpiderScheduler


def test_scheduler_initialization():
    """æµ‹è¯•è°ƒåº¦å™¨åˆå§‹åŒ–"""
    print("æµ‹è¯•è°ƒåº¦å™¨åˆå§‹åŒ–...")
    scheduler = SpiderScheduler(max_concurrent=3, delay_between_tasks=5)
    
    # æ£€æŸ¥åŸºæœ¬å±æ€§
    assert scheduler.max_concurrent == 3
    assert scheduler.delay_between_tasks == 5
    assert scheduler.running == False
    
    print("âœ… è°ƒåº¦å™¨åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")


def test_database_stats():
    """æµ‹è¯•æ•°æ®åº“ç»Ÿè®¡åŠŸèƒ½"""
    print("æµ‹è¯•æ•°æ®åº“ç»Ÿè®¡åŠŸèƒ½...")
    scheduler = SpiderScheduler()
    
    stats = scheduler.get_database_stats()
    if stats:
        print(f"  æ€»URLæ•°: {stats['total']}")
        print(f"  å·²å®Œæˆ: {stats['completed']}")
        print(f"  å¾…æŠ“å–: {stats['pending']}")
        print(f"  æŠ“å–ä¸­: {stats['crawling']}")
        print(f"  å¤±è´¥: {stats['failed']}")
        print("âœ… æ•°æ®åº“ç»Ÿè®¡æµ‹è¯•é€šè¿‡")
    else:
        print("âš ï¸ æ•°æ®åº“ä¸å­˜åœ¨æˆ–ä¸ºç©º")


def test_random_url_selection():
    """æµ‹è¯•éšæœºURLé€‰æ‹©åŠŸèƒ½"""
    print("æµ‹è¯•éšæœºURLé€‰æ‹©åŠŸèƒ½...")
    scheduler = SpiderScheduler()
    
    # æµ‹è¯•è·å–å•ä¸ªURL
    url = scheduler.get_random_pending_url()
    if url:
        print(f"  éšæœºURL: {url}")
        print("âœ… å•ä¸ªURLé€‰æ‹©æµ‹è¯•é€šè¿‡")
    else:
        print("âš ï¸ æ²¡æœ‰å¾…æŠ“å–çš„URL")
        return
    
    # æµ‹è¯•è·å–å¤šä¸ªURL
    urls = scheduler.get_multiple_random_pending_urls(3)
    if urls:
        print(f"  éšæœºURLs ({len(urls)}ä¸ª):")
        for i, url in enumerate(urls, 1):
            print(f"    {i}. {url}")
        print("âœ… å¤šä¸ªURLé€‰æ‹©æµ‹è¯•é€šè¿‡")
    else:
        print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„å¾…æŠ“å–URL")


def test_clean_stale_status():
    """æµ‹è¯•æ¸…ç†å¼‚å¸¸çŠ¶æ€åŠŸèƒ½"""
    print("æµ‹è¯•æ¸…ç†å¼‚å¸¸çŠ¶æ€åŠŸèƒ½...")
    scheduler = SpiderScheduler()
    
    try:
        scheduler.clean_stale_crawling_status()
        print("âœ… çŠ¶æ€æ¸…ç†æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ çŠ¶æ€æ¸…ç†æµ‹è¯•å¤±è´¥: {e}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¤šè¿›ç¨‹è°ƒåº¦å™¨åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    try:
        test_scheduler_initialization()
        print()
        
        test_database_stats()
        print()
        
        test_random_url_selection()
        print()
        
        test_clean_stale_status()
        print()
        
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()