#!/usr/bin/env python3
"""
æµ‹è¯•å…³é”®è¯è¿‡æ»¤åŠŸèƒ½
"""

from webspider.spiders.webspider import WebSpider


def test_keyword_filter():
    """æµ‹è¯•å…³é”®è¯è¿‡æ»¤åŠŸèƒ½"""
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    spider = WebSpider(start_url="https://example.com", enable_keyword_filter=True)
    
    # æµ‹è¯•ç›¸å…³é¡µé¢å†…å®¹
    relevant_html_samples = [
        """
        <html>
        <head><title>å›½å®¶è‡ªç„¶èµ„æºéƒ¨</title></head>
        <body>
        <h1>è‡ªç„¶èµ„æºç®¡ç†</h1>
        <p>åŠ å¼ºçŸ¿äº§èµ„æºå‹˜æ¢å’Œå¼€å‘ï¼Œæ¨è¿›åœ°è´¨è°ƒæŸ¥å·¥ä½œ...</p>
        </body>
        </html>
        """,
        
        """
        <html>
        <head><title>ä¸­å›½åœ°è´¨è°ƒæŸ¥å±€</title></head>
        <body>
        <h2>åœ°è´¨å‹˜æ¢æœ€æ–°è¿›å±•</h2>
        <p>æœ¬æ¬¡åœ°è´¨å‹˜æ¢å‘ç°äº†å¤§å‹é“œçŸ¿ï¼Œå‚¨é‡ä¸°å¯Œ...</p>
        </body>
        </html>
        """,
        
        """
        <html>
        <head><title>ç…¤ç‚­å¼€é‡‡å®‰å…¨ç®¡ç†</title></head>
        <body>
        <h1>çŸ¿å±±å®‰å…¨ç”Ÿäº§</h1>
        <p>ç¡®ä¿ç…¤çŸ¿å¼€é‡‡è¿‡ç¨‹ä¸­çš„å®‰å…¨ç”Ÿäº§...</p>
        </body>
        </html>
        """
    ]
    
    # æµ‹è¯•ä¸ç›¸å…³é¡µé¢å†…å®¹
    irrelevant_html_samples = [
        """
        <html>
        <head><title>ç¾é£Ÿæ¨è</title></head>
        <body>
        <h1>ä»Šæ—¥èœè°±</h1>
        <p>æ¨èå‡ é“ç¾å‘³å®¶å¸¸èœçš„åšæ³•...</p>
        </body>
        </html>
        """,
        
        """
        <html>
        <head><title>ä½“è‚²æ–°é—»</title></head>
        <body>
        <h2>è¶³çƒæ¯”èµ›ç»“æœ</h2>
        <p>æ˜¨æ™šçš„è¶³çƒæ¯”èµ›ç²¾å½©æ¿€çƒˆ...</p>
        </body>
        </html>
        """,
        
        """
        <html>
        <head><title>è´­ç‰©æŒ‡å—</title></head>
        <body>
        <h1>ç”µå­äº§å“è¯„æµ‹</h1>
        <p>æœ¬æœŸä¸ºå¤§å®¶è¯„æµ‹æœ€æ–°çš„æ™ºèƒ½æ‰‹æœº...</p>
        </body>
        </html>
        """
    ]
    
    print("ğŸ§ª æµ‹è¯•å…³é”®è¯è¿‡æ»¤åŠŸèƒ½")
    print("=" * 50)
    
    print("\nâœ… æµ‹è¯•ç›¸å…³é¡µé¢ï¼ˆåº”è¯¥é€šè¿‡è¿‡æ»¤ï¼‰:")
    for i, html in enumerate(relevant_html_samples, 1):
        result = spider.is_content_relevant(html, f"https://example{i}.com")
        status = "âœ… é€šè¿‡" if result else "âŒ è¢«è¿‡æ»¤"
        print(f"  æµ‹è¯•é¡µé¢ {i}: {status}")
    
    print("\nâŒ æµ‹è¯•ä¸ç›¸å…³é¡µé¢ï¼ˆåº”è¯¥è¢«è¿‡æ»¤ï¼‰:")
    for i, html in enumerate(irrelevant_html_samples, 1):
        result = spider.is_content_relevant(html, f"https://irrelevant{i}.com")
        status = "âŒ è¢«è¿‡æ»¤" if not result else "âš ï¸ è¯¯åˆ¤ä¸ºç›¸å…³"
        print(f"  æµ‹è¯•é¡µé¢ {i}: {status}")
    
    # æµ‹è¯•URLé¢„è¿‡æ»¤
    print("\nğŸ”— æµ‹è¯•URLé¢„è¿‡æ»¤åŠŸèƒ½:")
    
    relevant_urls = [
        "https://mnr.gov.cn/gk/",
        "https://www.cgs.gov.cn/",
        "https://example.com/mining/",
        "https://geology.org.cn/",
        "https://example.com/natural-resources/"
    ]
    
    irrelevant_urls = [
        "https://example.com/sports/",
        "https://example.com/food/",
        "https://example.com/entertainment/",
        "https://example.com/fashion/",
        "https://example.com/travel/"
    ]
    
    print("  ç›¸å…³URLï¼ˆåº”è¯¥é€šè¿‡ï¼‰:")
    for url in relevant_urls:
        result = spider.is_url_potentially_relevant(url)
        status = "âœ… é€šè¿‡" if result else "âŒ è¢«è¿‡æ»¤"
        print(f"    {url}: {status}")
    
    print("  ä¸ç›¸å…³URLï¼ˆåº”è¯¥è¢«è¿‡æ»¤ï¼‰:")
    for url in irrelevant_urls:
        result = spider.is_url_potentially_relevant(url)
        status = "âŒ è¢«è¿‡æ»¤" if not result else "âš ï¸ è¯¯åˆ¤ä¸ºç›¸å…³"
        print(f"    {url}: {status}")
    
    print(f"\nğŸ“‹ å…³é”®è¯åº“ä¿¡æ¯:")
    print(f"  æ€»å…³é”®è¯æ•°é‡: {len(spider.target_keywords)}")
    print(f"  å…³é”®è¯æ ·ä¾‹: {list(spider.target_keywords)[:10]}...")


def test_url_filtering():
    """æµ‹è¯•URLè¿‡æ»¤åŠŸèƒ½"""
    spider = WebSpider(start_url="https://example.com", enable_keyword_filter=True)
    
    test_urls = [
        # åº”è¯¥é€šè¿‡çš„URL
        ("https://mnr.gov.cn/", True, "æ”¿åºœç½‘ç«™"),
        ("https://example.com/mining/", True, "åŒ…å«miningå…³é”®è¯"),
        ("https://geology.org/", True, "åŒ…å«geologyå…³é”®è¯"),
        ("https://example.com/mineral/", True, "åŒ…å«mineralå…³é”®è¯"),
        
        # åº”è¯¥è¢«è¿‡æ»¤çš„URL
        ("https://example.com/sports/", False, "ä½“è‚²ç›¸å…³"),
        ("https://example.com/food/", False, "ç¾é£Ÿç›¸å…³"),
        ("https://example.com/image.jpg", False, "å›¾ç‰‡æ–‡ä»¶"),
        ("https://example.com/style.css", False, "æ ·å¼æ–‡ä»¶"),
        ("https://example.com/api/data", False, "APIæ¥å£"),
    ]
    
    print("\nğŸ” URLè¿‡æ»¤æµ‹è¯•:")
    print("-" * 30)
    
    for url, expected, description in test_urls:
        result = spider.should_crawl_url(url)
        status = "âœ…" if result == expected else "âŒ"
        print(f"{status} {url} - {description}")
        if result != expected:
            print(f"   é¢„æœŸ: {'é€šè¿‡' if expected else 'è¿‡æ»¤'}, å®é™…: {'é€šè¿‡' if result else 'è¿‡æ»¤'}")


if __name__ == '__main__':
    test_keyword_filter()
    test_url_filtering()
    
    print("\nğŸ¯ ä½¿ç”¨å»ºè®®:")
    print("1. é»˜è®¤å¯ç”¨å…³é”®è¯è¿‡æ»¤ï¼ŒåªæŠ“å–ç›¸å…³é¡µé¢")
    print("2. ä½¿ç”¨ --no-filter å‚æ•°å¯ä»¥ç¦ç”¨è¿‡æ»¤ï¼ŒæŠ“å–æ‰€æœ‰é¡µé¢")
    print("3. è¿‡æ»¤å™¨ä¼šæ£€æŸ¥é¡µé¢æ ‡é¢˜ã€metaä¿¡æ¯ã€æ ‡é¢˜æ ‡ç­¾å’Œæ­£æ–‡å†…å®¹")
    print("4. URLé¢„è¿‡æ»¤å¯ä»¥å‡å°‘ä¸å¿…è¦çš„è¯·æ±‚ï¼Œæé«˜æ•ˆç‡")