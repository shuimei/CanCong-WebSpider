# 快速使用指南

## 🕷️ 网页爬虫项目已就绪！

您的基于Scrapy的智能网页爬虫已经创建完成，具备以下功能：

### ✅ 核心功能
- **JavaScript渲染**: 使用Selenium支持动态网页
- **智能去重**: SQLite数据库记录URL状态，避免重复抓取  
- **深度控制**: 可配置抓取深度，防止无限递归
- **内容保存**: 自动保存HTML文件和元数据
- **错误处理**: 完善的错误处理和重试机制
- **统计信息**: 实时显示抓取进度

### 🚀 快速开始

#### 1. 安装依赖（如果尚未安装）
```bash
# Windows
install.bat

# 或手动安装
pip install -r requirements.txt
```

#### 2. 基本使用
```bash
# 抓取网站（交互式）
python spider.py

# 直接抓取指定URL
python spider.py https://example.com

# 指定深度和延迟
python spider.py https://example.com --depth 3 --delay 1

# 高并发抓取
python spider.py https://example.com --concurrent 8 --delay 0.5
```

#### 3. 管理和统计
```bash
# 查看统计信息
python spider.py --stats

# 清理长时间未完成的任务
python spider.py --clean

# 重置数据库（删除所有数据）
python spider.py --reset
```

### 📁 文件结构
```
spider/
├── spider.py                 # 主启动脚本（推荐使用）
├── run_spider.py             # 核心运行脚本
├── requirements.txt          # Python依赖
├── install.bat              # Windows安装脚本
├── test_spider.py           # 测试脚本
├── README.md                # 详细文档
├── webspider/               # 爬虫核心模块
│   ├── settings.py          # Scrapy配置
│   ├── database.py          # SQLite数据库管理
│   ├── middlewares.py       # JS渲染和去重中间件
│   ├── pipelines.py         # 数据处理管道
│   └── spiders/
│       └── webspider.py     # 主爬虫逻辑
├── webpages/                # HTML文件存储目录
└── spider_urls.db           # SQLite数据库文件
```

### 💡 使用提示

1. **JavaScript支持**: 程序会自动检测需要JS渲染的页面并使用Chrome浏览器
2. **去重机制**: URL会自动去重，避免重复抓取相同页面
3. **状态管理**: 可以中断后恢复，程序会记住抓取进度
4. **文件命名**: HTML文件使用URL哈希命名，避免文件名冲突

### ⚠️ 注意事项

1. **Chrome浏览器**: 确保已安装Chrome浏览器（JS渲染需要）
2. **性能**: JavaScript渲染会增加抓取时间，合理设置并发数和延迟
3. **合规性**: 请遵守网站robots.txt和服务条款
4. **资源**: 注意系统内存和磁盘空间

### 📊 示例输出
```
开始爬取: https://example.com
最大深度: 2
输出目录: webpages
数据库文件: spider_urls.db
--------------------------------------------------

==========统计信息==========
运行时间: 0:05:23
已处理页面: 45
总URL数: 156
待抓取: 23
抓取成功: 42
抓取失败: 3
正在抓取: 1
===========================
```

### 🔧 高级配置

如需自定义配置，请编辑：
- `webspider/settings.py` - Scrapy基本设置
- `webspider/pipelines.py` - 数据处理逻辑
- `webspider/middlewares.py` - 中间件配置

---

🎉 **现在就可以开始使用您的网页爬虫了！**

输入 `python spider.py` 开始交互式抓取，或查看 `README.md` 了解更多详细信息。