# Qoderå®è·µï¼šä¸€ä¸ªå…¨èƒ½çš„ç½‘ç»œçˆ¬è™«ç³»ç»Ÿ

## å‰è¨€

åœ¨AIç¼–ç¨‹å·¥å…·æ—¥ç›Šæ™®åŠçš„ä»Šå¤©ï¼Œå¦‚ä½•é«˜æ•ˆåœ°æ„å»ºä¸€ä¸ªåŠŸèƒ½å®Œå¤‡çš„ç½‘ç»œçˆ¬è™«ç³»ç»Ÿï¼Ÿæœ¬æ–‡å°†åˆ†äº«æˆ‘ä½¿ç”¨Qoderè¿™ä¸€æ–°å…´AIç¼–ç¨‹åŠ©æ‰‹çš„å®è·µç»éªŒï¼Œä»é›¶å¼€å§‹æ„å»ºäº†ä¸€ä¸ªé›†æ•°æ®æŠ“å–ã€æ™ºèƒ½è¿‡æ»¤ã€å†…å®¹æ¸…æ´—ã€å®æ—¶ç›‘æ§äºä¸€ä½“çš„å…¨èƒ½çˆ¬è™«ç³»ç»Ÿã€‚

## é¡¹ç›®æ¦‚è§ˆ

è¿™ä¸ªçˆ¬è™«ç³»ç»Ÿä¸“é—¨ç”¨äºæŠ“å–çŸ¿å±±ã€è‡ªç„¶èµ„æºã€åœ°è´¨ç­‰æ”¿åºœç½‘ç«™çš„å†…å®¹ï¼Œå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒç‰¹æ€§ï¼š

- ğŸ¯ **æ™ºèƒ½å…³é”®è¯è¿‡æ»¤**ï¼š93ä¸ªä¸“ä¸šå…³é”®è¯ï¼Œå¤šå±‚æ¬¡æƒé‡è¯„åˆ†
- ğŸ”„ **é«˜æ•ˆå»é‡æœºåˆ¶**ï¼šSQLiteæ•°æ®åº“ç®¡ç†ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
- ğŸ² **éšæœºæŠ“å–åŠŸèƒ½**ï¼šçœŸæ­£çš„éšæœºç®—æ³•ï¼Œé¿å…æŠ“å–æ¨¡å¼è¢«è¯†åˆ«
- ğŸŒ **å®æ—¶Webç›‘æ§**ï¼šVue.js + FastAPIæ„å»ºçš„ç°ä»£åŒ–ç•Œé¢
- âš¡ **JavaScriptæ¸²æŸ“**ï¼šSeleniumæ”¯æŒåŠ¨æ€ç½‘é¡µå†…å®¹
- ğŸ§¹ **æ™ºèƒ½å†…å®¹æ¸…æ´—**ï¼šHTMLè½¬Markdownï¼Œè¿‡æ»¤æ— å…³å†…å®¹

## æŠ€æœ¯æ¶æ„

### æ ¸å¿ƒæŠ€æœ¯æ ˆ

```
åç«¯ï¼šPython + Scrapy + Selenium + SQLite + FastAPI
å‰ç«¯ï¼šVue.js 3 + Bootstrap 5 + Chart.js
å·¥å…·ï¼šhtml2text + markdownify
```

### ç³»ç»Ÿæ¶æ„å›¾

```mermaid
graph TB
    A[ç”¨æˆ·æ¥å£] --> B[çˆ¬è™«æ§åˆ¶å™¨]
    B --> C[Scrapyå¼•æ“]
    C --> D[ä¸‹è½½ä¸­é—´ä»¶]
    D --> E[JavaScriptæ¸²æŸ“]
    E --> F[å“åº”å¤„ç†]
    F --> G[å†…å®¹è¿‡æ»¤å™¨]
    G --> H[æ•°æ®ç®¡é“]
    H --> I[SQLiteæ•°æ®åº“]
    H --> J[HTMLæ–‡ä»¶å­˜å‚¨]
    J --> K[å†…å®¹æ¸…æ´—å™¨]
    K --> L[Markdownè¾“å‡º]
    
    M[Webç›‘æ§ç•Œé¢] --> N[FastAPIåç«¯]
    N --> I
    N --> O[å®æ—¶ç»Ÿè®¡]
    O --> P[å›¾è¡¨å±•ç¤º]
```

## æ ¸å¿ƒåŠŸèƒ½å®ç°

### 1. æ™ºèƒ½å…³é”®è¯è¿‡æ»¤ç³»ç»Ÿ

è¿™æ˜¯æ•´ä¸ªç³»ç»Ÿçš„æ ¸å¿ƒäº®ç‚¹ã€‚æˆ‘ä»¬å®ç°äº†ä¸€å¥—å¤šå±‚æ¬¡çš„å†…å®¹è¯„åˆ†æœºåˆ¶ï¼š

```python
def is_content_relevant(self, html_content, url):
    """æ£€æŸ¥é¡µé¢å†…å®¹æ˜¯å¦ä¸çŸ¿å±±ã€è‡ªç„¶èµ„æºã€åœ°è´¨ç›¸å…³"""
    # æå–ä¸åŒæƒé‡çš„æ–‡æœ¬å†…å®¹
    title_text = self.extract_title(soup) * 5      # æ ‡é¢˜æƒé‡5å€
    meta_text = self.extract_meta(soup) * 3        # metaæƒé‡3å€  
    heading_text = self.extract_headings(soup) * 2 # æ ‡é¢˜æƒé‡2å€
    page_text = self.extract_content(soup)          # æ­£æ–‡æƒé‡1å€
    
    # åŠ æƒå†…å®¹è¯„åˆ†
    weighted_content = title_text + meta_text + heading_text + page_text
    
    # å…³é”®è¯åŒ¹é…å’Œè®¡åˆ†
    matched_keywords = []
    keyword_score = 0
    for keyword in self.target_keywords:
        if keyword in weighted_content:
            matched_keywords.append(keyword)
            keyword_score += weighted_content.count(keyword)
    
    # åˆ¤æ–­æ ‡å‡†ï¼šåŒ¹é…å…³é”®è¯â‰¥2ä¸ªæˆ–æ€»æƒé‡â‰¥5åˆ†
    return len(matched_keywords) >= 2 or keyword_score >= 5
```

**å…³é”®è¯åº“è®¾è®¡**ï¼š
- çŸ¿å±±ç›¸å…³ï¼šçŸ¿å±±ã€çŸ¿ä¸šã€é‡‡çŸ¿ã€çŸ¿äº•ã€çŸ¿ç‰©ã€å¼€é‡‡ç­‰
- èµ„æºç›¸å…³ï¼šè‡ªç„¶èµ„æºã€å›½åœŸèµ„æºã€æ°´èµ„æºã€æ£®æ—èµ„æºç­‰  
- åœ°è´¨ç›¸å…³ï¼šåœ°è´¨å‹˜æ¢ã€åœ°è´¨è°ƒæŸ¥ã€å²©çŸ³ã€åœ°å±‚ã€æ–­å±‚ç­‰
- æœºæ„æœ¯è¯­ï¼šè‡ªç„¶èµ„æºéƒ¨ã€åœ°è´¨è°ƒæŸ¥å±€ã€å‹˜å¯Ÿè®¾è®¡ç­‰

### 2. é«˜æ•ˆå»é‡ä¸çŠ¶æ€ç®¡ç†

ä½¿ç”¨SQLiteæ•°æ®åº“å®ç°URLçŠ¶æ€çš„ç²¾ç¡®ç®¡ç†ï¼š

```python
class UrlDatabase:
    def __init__(self):
        self.conn = sqlite3.connect('spider_urls.db')
        self.setup_database()
    
    def add_url(self, url, source_url=None, depth=0):
        """æ·»åŠ URLåˆ°å¾…æŠ“å–é˜Ÿåˆ—"""
        normalized_url = normalize_url(url)
        cursor = self.conn.cursor()
        
        cursor.execute('''
            INSERT OR IGNORE INTO urls 
            (url, normalized_url, source_url, depth, status, created_at)
            VALUES (?, ?, ?, ?, 'pending', datetime('now'))
        ''', (url, normalized_url, source_url, depth))
        
        return cursor.rowcount > 0
    
    def get_random_pending_urls(self, limit=10):
        """éšæœºè·å–å¾…æŠ“å–URL"""
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT url, depth FROM urls 
            WHERE status = 'pending' 
            ORDER BY RANDOM() 
            LIMIT ?
        ''', (limit,))
        return cursor.fetchall()
```

**æ•°æ®åº“è®¾è®¡äº®ç‚¹**ï¼š
- ä½¿ç”¨normalized_urlå­—æ®µé¿å…å‚æ•°é¡ºåºå¯¼è‡´çš„é‡å¤
- æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œç³»ç»Ÿé‡å¯åå¯ç»§ç»­ä¹‹å‰çš„ä»»åŠ¡
- è®°å½•æŠ“å–çŠ¶æ€å’Œæ—¶é—´æˆ³ï¼Œä¾¿äºåˆ†æå’Œè°ƒè¯•

### 3. åŠ¨æ€ç½‘é¡µæ¸²æŸ“æ”¯æŒ

ç°ä»£ç½‘ç«™å¤§é‡ä½¿ç”¨JavaScriptï¼Œä¼ ç»Ÿçˆ¬è™«å¾€å¾€æŸæ‰‹æ— ç­–ã€‚æˆ‘ä»¬é›†æˆäº†Seleniumï¼š

```python
class JavaScriptMiddleware:
    def __init__(self):
        self.driver_pool = DriverPool(max_drivers=3)
    
    def process_request(self, request, spider):
        if request.meta.get('render_js'):
            driver = self.driver_pool.get_driver()
            try:
                driver.get(request.url)
                # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
                # æ‰§è¡Œé¡µé¢æ»šåŠ¨ï¼Œè§¦å‘æ‡’åŠ è½½
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                html_content = driver.page_source
                return HtmlResponse(url=request.url, body=html_content, encoding='utf-8')
            finally:
                self.driver_pool.return_driver(driver)
```

### 4. æ™ºèƒ½å†…å®¹æ¸…æ´—ç³»ç»Ÿ

è¿™æ˜¯é¡¹ç›®çš„å¦ä¸€ä¸ªåˆ›æ–°ç‚¹ã€‚åŸå§‹HTMLåŒ…å«å¤§é‡æ— å…³å†…å®¹ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€å¥—æ™ºèƒ½æ¸…æ´—ç®—æ³•ï¼š

```python
class HTMLCleaner:
    def __init__(self, min_content_length=200):
        self.min_content_length = min_content_length
        
        # å¯¼èˆªèœå•è¯†åˆ«æ¨¡å¼
        self.nav_patterns = [
            r'é¦–é¡µ[\s|>]*', r'å½“å‰ä½ç½®[\s:ï¼š]*', r'æ‚¨ç°åœ¨çš„ä½ç½®[\s:ï¼š]*',
            r'å¯¼èˆª[\s:ï¼š]*', r'é¢åŒ…å±‘[\s:ï¼š]*', r'>>\\s*', r'æ›´å¤š[>>]*'
        ]
        
        # éœ€è¦ç§»é™¤çš„æ ‡ç­¾å’Œç±»å
        self.unwanted_tags = ['nav', 'header', 'footer', 'aside', 'script']
        self.unwanted_classes = ['navigation', 'sidebar', 'ad', 'social']
    
    def assess_content_quality(self, text):
        """äº”çº§è´¨é‡è¯„åˆ†ç³»ç»Ÿ"""
        # 1. é•¿åº¦å¾—åˆ†ï¼ˆ20åˆ†ï¼‰
        length_score = min(20, len(text) / 50)
        
        # 2. ç»“æ„å®Œæ•´æ€§ï¼ˆ20åˆ†ï¼‰  
        structure_score = self.calculate_structure_score(text)
        
        # 3. å®è´¨å†…å®¹æ¯”ä¾‹ï¼ˆ30åˆ†ï¼‰
        content_ratio = self.calculate_content_ratio(text)
        content_score = content_ratio * 30
        
        # 4. å¯¼èˆªå†…å®¹è¿‡æ»¤ï¼ˆ20åˆ†ï¼‰
        nav_score = self.calculate_nav_filter_score(text)
        
        # 5. é¢†åŸŸç›¸å…³æ€§ï¼ˆ10åˆ†ï¼‰
        domain_score = self.calculate_domain_relevance(text)
        
        total_score = length_score + structure_score + content_score + nav_score + domain_score
        return total_score, {
            'length': length_score,
            'structure': structure_score, 
            'content': content_score,
            'nav_filter': nav_score,
            'domain': domain_score
        }
```

**è´¨é‡æ§åˆ¶æ ‡å‡†**ï¼š
- æœ€å°å†…å®¹é•¿åº¦ï¼š200å­—ç¬¦
- è´¨é‡è¯„åˆ†é˜ˆå€¼ï¼š40åˆ†ï¼ˆæ»¡åˆ†100åˆ†ï¼‰
- è‡ªåŠ¨è¿‡æ»¤å¯¼èˆªèœå•å’Œæ— å…³å†…å®¹
- æ™ºèƒ½è¯†åˆ«å¹¶æå–ä¸»è¦å†…å®¹åŒºåŸŸ

### 5. å®æ—¶Webç›‘æ§ç•Œé¢

ä½¿ç”¨FastAPI + Vue.jsæ„å»ºç°ä»£åŒ–çš„ç›‘æ§ç•Œé¢ï¼š

```python
from fastapi import FastAPI, WebSocket
from fastapi.staticfiles import StaticFiles
import asyncio

app = FastAPI(title="çˆ¬è™«ç›‘æ§ç³»ç»Ÿ")

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    try:
        while True:
            # å®æ—¶æ¨é€ç»Ÿè®¡æ•°æ®
            stats = get_spider_stats()
            await websocket.send_json(stats)
            await asyncio.sleep(1)
    except WebSocketDisconnect:
        pass

@app.get("/api/stats")
async def get_statistics():
    """è·å–æŠ“å–ç»Ÿè®¡ä¿¡æ¯"""
    db = UrlDatabase()
    return {
        'total_urls': db.get_total_count(),
        'pending': db.get_pending_count(),
        'completed': db.get_completed_count(),
        'failed': db.get_failed_count(),
        'success_rate': db.get_success_rate()
    }
```

**ç›‘æ§ç•Œé¢ç‰¹æ€§**ï¼š
- å®æ—¶æ•°æ®æ›´æ–°ï¼ˆWebSocketæ¨é€ï¼‰
- å¯è§†åŒ–å›¾è¡¨å±•ç¤ºï¼ˆChart.jsï¼‰
- çˆ¬è™«çŠ¶æ€ç›‘æ§
- é”™è¯¯æ—¥å¿—æŸ¥çœ‹
- æ‰‹åŠ¨æ§åˆ¶å¯åœ

## é¡¹ç›®ç»“æ„ä¸æœ€ä½³å®è·µ

### ç›®å½•ç»„ç»‡

```
spider/
â”œâ”€â”€ spider.py                    # ä¸»å¯åŠ¨è„šæœ¬
â”œâ”€â”€ run_spider.py               # æ ¸å¿ƒè¿è¡Œè„šæœ¬
â”œâ”€â”€ webspider/                  # çˆ¬è™«æºç åŒ…
â”‚   â”œâ”€â”€ spiders/webspider.py    # ä¸»çˆ¬è™«ç±»
â”‚   â”œâ”€â”€ database.py             # æ•°æ®åº“ç®¡ç†
â”‚   â”œâ”€â”€ middlewares.py          # ä¸­é—´ä»¶
â”‚   â””â”€â”€ pipelines.py            # æ•°æ®ç®¡é“
â”œâ”€â”€ frontend/                   # Webç›‘æ§ç•Œé¢
â”‚   â”œâ”€â”€ main.py                 # FastAPIæœåŠ¡å™¨
â”‚   â””â”€â”€ templates/index.html    # Vue.jså‰ç«¯
â”œâ”€â”€ scripts/                    # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ html_cleaner.py         # HTMLæ¸…æ´—å·¥å…·
â”‚   â”œâ”€â”€ clean_duplicates.py     # é‡å¤æ–‡ä»¶æ¸…ç†
â”‚   â””â”€â”€ start_monitor.py        # ç›‘æ§å¯åŠ¨è„šæœ¬
â”œâ”€â”€ tests/                      # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ docs/                       # æ–‡æ¡£ç›®å½•
â”œâ”€â”€ webpages/                   # åŸå§‹HTMLå­˜å‚¨
â”œâ”€â”€ mdpages/                    # æ¸…æ´—åMarkdown
â””â”€â”€ spider_urls.db             # SQLiteæ•°æ®åº“
```

### é…ç½®ç®¡ç†

ä½¿ç”¨Scrapyçš„settings.pyè¿›è¡Œç»Ÿä¸€é…ç½®ï¼š

```python
# åŸºç¡€è®¾ç½®
BOT_NAME = 'webspider'
ROBOTSTXT_OBEY = False
CONCURRENT_REQUESTS = 16
DOWNLOAD_DELAY = 1
RANDOMIZE_DOWNLOAD_DELAY = 0.5

# ä¸­é—´ä»¶é…ç½®
DOWNLOADER_MIDDLEWARES = {
    'webspider.middlewares.UrlFilterMiddleware': 300,
    'webspider.middlewares.JavaScriptMiddleware': 400,
    'webspider.middlewares.RandomUserAgentMiddleware': 500,
}

# ç®¡é“é…ç½®
ITEM_PIPELINES = {
    'webspider.pipelines.DuplicatesPipeline': 300,
    'webspider.pipelines.HtmlStoragePipeline': 400,
    'webspider.pipelines.DatabasePipeline': 500,
}

# JavaScriptæ¸²æŸ“è®¾ç½®
SELENIUM_DRIVER_NAME = 'chrome'
SELENIUM_DRIVER_EXECUTABLE_PATH = None  # è‡ªåŠ¨æ£€æµ‹
SELENIUM_DRIVER_ARGUMENTS = ['--headless', '--no-sandbox']
```

## æ€§èƒ½ä¼˜åŒ–ä¸æ‰©å±•æ€§

### 1. æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

**å¹¶å‘æ§åˆ¶**ï¼š
- åˆç†è®¾ç½®å¹¶å‘è¯·æ±‚æ•°ï¼ˆ16ä¸ªï¼‰
- éšæœºä¸‹è½½å»¶è¿Ÿï¼ˆ0.5-1.5ç§’ï¼‰
- è¿æ¥æ± å¤ç”¨
- å¼‚æ­¥I/Oæ“ä½œ

**å†…å­˜ç®¡ç†**ï¼š
- åŠæ—¶é‡Šæ”¾Selenium WebDriver
- æ•°æ®åº“è¿æ¥æ± 
- å¤§æ–‡ä»¶æµå¼å¤„ç†
- åƒåœ¾å›æ”¶ä¼˜åŒ–

**ç¼“å­˜æœºåˆ¶**ï¼š
- HTTPå“åº”ç¼“å­˜
- DNSè§£æç¼“å­˜
- é™æ€èµ„æºCDN
- æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜

### 2. æ‰©å±•æ€§è®¾è®¡

**æ¨¡å—åŒ–æ¶æ„**ï¼š
æ¯ä¸ªåŠŸèƒ½æ¨¡å—ç‹¬ç«‹è®¾è®¡ï¼Œä¾¿äºæ‰©å±•å’Œç»´æŠ¤ï¼š

```python
# æ’ä»¶å¼è¿‡æ»¤å™¨
class ContentFilter:
    def __init__(self):
        self.filters = [
            KeywordFilter(),
            LengthFilter(), 
            QualityFilter(),
            DomainFilter()
        ]
    
    def apply_filters(self, content):
        for filter_instance in self.filters:
            if not filter_instance.accept(content):
                return False
        return True

# å¯é…ç½®çš„å­˜å‚¨åç«¯
class StorageBackend:
    def get_backend(self, backend_type):
        backends = {
            'file': FileStorage(),
            'database': DatabaseStorage(),
            'cloud': CloudStorage()
        }
        return backends.get(backend_type, FileStorage())
```

## å®é™…æ•ˆæœä¸æ•°æ®

### æŠ“å–æ•ˆæœç»Ÿè®¡

ç»è¿‡å®é™…æµ‹è¯•ï¼Œç³»ç»Ÿåœ¨å¤„ç†æ”¿åºœç½‘ç«™æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼š

- **æ•°æ®æº**ï¼šè‡ªç„¶èµ„æºéƒ¨ã€å„çœåœ°è´¨å±€ç­‰å®˜æ–¹ç½‘ç«™
- **æŠ“å–ç½‘é¡µ**ï¼š693ä¸ªHTMLæ–‡ä»¶
- **è´¨é‡è¿‡æ»¤å**ï¼š92ä¸ªé«˜è´¨é‡Markdownæ–‡ä»¶
- **è¿‡æ»¤æ•ˆç‡**ï¼š86.7%çš„å™ªå£°å†…å®¹è¢«è¿‡æ»¤
- **å¹³å‡å¤„ç†é€Ÿåº¦**ï¼š200ms/é¡µé¢
- **å†…å®¹è´¨é‡è¯„åˆ†**ï¼šå¹³å‡65åˆ†ï¼ˆæ»¡åˆ†100åˆ†ï¼‰

### å†…å®¹æ¸…æ´—æ•ˆæœå¯¹æ¯”

**å¤„ç†å‰**ï¼ˆåŸå§‹HTMLï¼‰ï¼š
```html
<nav class="navbar">
  <div class="breadcrumb">é¦–é¡µ > æ”¿åŠ¡å…¬å¼€ > æœ€æ–°å…¬æŠ¥</div>
</nav>
<div class="sidebar">...</div>
<article class="main-content">
  <h1>æ±Ÿè‹çœå›°éš¾é€€å½¹å†›äººå¸®æ‰¶æ´åŠ©å·¥ä½œå®æ–½åŠæ³•</h1>
  <p>ä¸ºè¿›ä¸€æ­¥æ¨è¿›æˆ‘çœå›°éš¾é€€å½¹å†›äººå¸®æ‰¶æ´åŠ©å·¥ä½œ...</p>
</article>
<footer>ç‰ˆæƒæ‰€æœ‰...</footer>
```

**å¤„ç†å**ï¼ˆæ¸…æ´—çš„Markdownï¼‰ï¼š
```markdown
# æ±Ÿè‹çœå›°éš¾é€€å½¹å†›äººå¸®æ‰¶æ´åŠ©å·¥ä½œå®æ–½åŠæ³•

ä¸ºè¿›ä¸€æ­¥æ¨è¿›æˆ‘çœå›°éš¾é€€å½¹å†›äººå¸®æ‰¶æ´åŠ©å·¥ä½œè§„èŒƒåŒ–ã€åˆ¶åº¦åŒ–å»ºè®¾ï¼Œæ ¹æ®ã€Šä¸­åäººæ°‘å…±å’Œå›½é€€å½¹å†›äººä¿éšœæ³•ã€‹...

## ç¬¬ä¸€ç«  æ€»åˆ™

ç¬¬ä¸€æ¡ æ ¹æ®ã€Šä¸­åäººæ°‘å…±å’Œå›½é€€å½¹å†›äººä¿éšœæ³•ã€‹ç­‰æ³•å¾‹æ³•è§„è§„å®š...
```

å¯ä»¥çœ‹åˆ°ï¼Œç³»ç»ŸæˆåŠŸç§»é™¤äº†å¯¼èˆªã€ä¾§è¾¹æ ã€é¡µè„šç­‰æ— å…³å†…å®¹ï¼Œä¿ç•™äº†æ ¸å¿ƒçš„æ”¿ç­–æ–‡ä»¶å†…å®¹ã€‚

## å¼€å‘å¿ƒå¾—ä¸æœ€ä½³å®è·µ

### 1. Qoderä½¿ç”¨ä½“éªŒ

**ä¼˜åŠ¿**ï¼š
- **æ™ºèƒ½ä»£ç ç”Ÿæˆ**ï¼šèƒ½å¤Ÿæ ¹æ®éœ€æ±‚å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡ä»£ç æ¡†æ¶
- **é—®é¢˜è¯Šæ–­èƒ½åŠ›**ï¼šå‡†ç¡®è¯†åˆ«å’Œä¿®å¤ä»£ç ä¸­çš„é—®é¢˜
- **æ–‡æ¡£ç”Ÿæˆ**ï¼šè‡ªåŠ¨ç”Ÿæˆè¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£å’Œä½¿ç”¨è¯´æ˜
- **æœ€ä½³å®è·µå»ºè®®**ï¼šæä¾›ä¸“ä¸šçš„æ¶æ„è®¾è®¡å’Œä¼˜åŒ–å»ºè®®

**åä½œæ¨¡å¼**ï¼š
- æˆ‘è´Ÿè´£éœ€æ±‚åˆ†æå’Œæ¶æ„è®¾è®¡
- Qoderè´Ÿè´£ä»£ç å®ç°å’Œé—®é¢˜ä¿®å¤
- è¿­ä»£ä¼˜åŒ–ï¼Œé€æ­¥å®Œå–„åŠŸèƒ½

### 2. å¼€å‘è¿‡ç¨‹ä¸­çš„æŒ‘æˆ˜

**æŠ€æœ¯æŒ‘æˆ˜**ï¼š
1. **JavaScriptæ¸²æŸ“**ï¼šéƒ¨åˆ†æ”¿åºœç½‘ç«™ä½¿ç”¨å¤æ‚çš„JSæ¡†æ¶
2. **åçˆ¬æœºåˆ¶**ï¼šéœ€è¦æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
3. **å†…å®¹è¯†åˆ«**ï¼šå‡†ç¡®åŒºåˆ†æœ‰ä»·å€¼å†…å®¹å’Œå™ªå£°ä¿¡æ¯
4. **æ€§èƒ½å¹³è¡¡**ï¼šåœ¨è´¨é‡å’Œæ•ˆç‡ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ç‚¹

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. **å¤šå±‚æ¸²æŸ“ç­–ç•¥**ï¼šä¼˜å…ˆä½¿ç”¨é™æ€æŠ“å–ï¼Œå¿…è¦æ—¶å¯ç”¨JSæ¸²æŸ“
2. **æ™ºèƒ½å»¶è¿Ÿ**ï¼šéšæœºè¯·æ±‚é—´éš”ï¼Œæ¨¡æ‹Ÿäººå·¥æµè§ˆ
3. **æœºå™¨å­¦ä¹ è¾…åŠ©**ï¼šç»“åˆè§„åˆ™å’Œæ¨¡å¼è¯†åˆ«
4. **åˆ†å±‚å¤„ç†**ï¼šå…³é”®å†…å®¹ä¼˜å…ˆï¼Œæ‰¹é‡å¤„ç†é™ä½å»¶è¿Ÿ

### 3. é¡¹ç›®ç®¡ç†ç»éªŒ

**ç‰ˆæœ¬æ§åˆ¶**ï¼š
- åŠŸèƒ½æ¨¡å—ç‹¬ç«‹å¼€å‘
- è¯¦ç»†çš„commit message
- åˆ†æ”¯ç®¡ç†ç­–ç•¥

**æµ‹è¯•é©±åŠ¨**ï¼š
- å•å…ƒæµ‹è¯•è¦†ç›–æ ¸å¿ƒåŠŸèƒ½
- é›†æˆæµ‹è¯•éªŒè¯ç«¯åˆ°ç«¯æµç¨‹
- æ€§èƒ½æµ‹è¯•ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§

**æ–‡æ¡£ç»´æŠ¤**ï¼š
- APIæ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ
- ç”¨æˆ·æ‰‹å†ŒæŒç»­æ›´æ–°
- å¼€å‘æ—¥å¿—è®°å½•å†³ç­–è¿‡ç¨‹

## æœªæ¥è§„åˆ’

### çŸ­æœŸä¼˜åŒ–ï¼ˆ1-2ä¸ªæœˆï¼‰

1. **æ™ºèƒ½å»é‡å¢å¼º**ï¼šåŸºäºå†…å®¹ç›¸ä¼¼åº¦çš„å»é‡ç®—æ³•
2. **åˆ†å¸ƒå¼éƒ¨ç½²**ï¼šæ”¯æŒå¤šæœºå™¨ååŒæŠ“å–
3. **æ•°æ®å¯è§†åŒ–**ï¼šæ›´ä¸°å¯Œçš„ç»Ÿè®¡å›¾è¡¨å’Œåˆ†æåŠŸèƒ½
4. **APIæ¥å£**ï¼šæä¾›RESTful APIä¾›ç¬¬ä¸‰æ–¹è°ƒç”¨

### é•¿æœŸå‘å±•ï¼ˆ3-6ä¸ªæœˆï¼‰

1. **æœºå™¨å­¦ä¹ é›†æˆ**ï¼š
   - æ™ºèƒ½å†…å®¹åˆ†ç±»
   - è‡ªåŠ¨å…³é”®è¯æå–
   - ç½‘ç«™ç»“æ„è¯†åˆ«

2. **äº‘åŸç”Ÿéƒ¨ç½²**ï¼š
   - Dockerå®¹å™¨åŒ–
   - Kubernetesç¼–æ’
   - å¾®æœåŠ¡æ¶æ„

3. **æ•°æ®å¤„ç†å¢å¼º**ï¼š
   - å®æ—¶æ•°æ®æµå¤„ç†
   - å¤§æ•°æ®åˆ†æé›†æˆ
   - çŸ¥è¯†å›¾è°±æ„å»º

## æ€»ç»“

é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘æ·±åˆ»ä½“éªŒåˆ°äº†AIç¼–ç¨‹åŠ©æ‰‹åœ¨å¤æ‚ç³»ç»Ÿå¼€å‘ä¸­çš„å·¨å¤§ä»·å€¼ã€‚Qoderä¸ä»…æé«˜äº†å¼€å‘æ•ˆç‡ï¼Œæ›´é‡è¦çš„æ˜¯æä¾›äº†ä¸“ä¸šçš„æŠ€æœ¯æŒ‡å¯¼å’Œæœ€ä½³å®è·µå»ºè®®ã€‚

**å…³é”®æ”¶è·**ï¼š

1. **AIåä½œå¼€å‘æ¨¡å¼**ï¼šäººæœºåä½œèƒ½å¤Ÿæ˜¾è‘—æå‡å¼€å‘è´¨é‡å’Œæ•ˆç‡
2. **ç³»ç»ŸåŒ–æ€ç»´**ï¼šä»éœ€æ±‚åˆ†æåˆ°éƒ¨ç½²è¿ç»´çš„å…¨é“¾è·¯è€ƒè™‘
3. **è´¨é‡ä¸æ•ˆç‡å¹³è¡¡**ï¼šåœ¨åŠŸèƒ½å®Œå¤‡æ€§å’Œç³»ç»Ÿæ€§èƒ½ä¹‹é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡
4. **æŒç»­ä¼˜åŒ–ç²¾ç¥**ï¼šç³»ç»Ÿè®¾è®¡è¦è€ƒè™‘é•¿æœŸæ¼”è¿›å’Œæ‰©å±•

è¿™ä¸ªçˆ¬è™«ç³»ç»Ÿå·²ç»åœ¨å®é™…åº”ç”¨ä¸­å‘æŒ¥ä½œç”¨ï¼ŒæˆåŠŸæŠ“å–å’Œæ¸…æ´—äº†å¤§é‡æ”¿åºœç½‘ç«™çš„é«˜è´¨é‡å†…å®¹ã€‚å¦‚æœä½ ä¹Ÿåœ¨å¼€å‘ç±»ä¼¼çš„æ•°æ®é‡‡é›†ç³»ç»Ÿï¼Œå¸Œæœ›è¿™äº›ç»éªŒèƒ½å¤Ÿä¸ºä½ æä¾›å‚è€ƒå’Œå¯å‘ã€‚

## å¼€æºä»£ç 

é¡¹ç›®ä»£ç å·²åœ¨GitHubå¼€æºï¼Œæ¬¢è¿starå’Œæäº¤PRï¼š
[github.com/your-username/smart-web-spider](https://github.com/your-username/smart-web-spider)

æ¬¢è¿åœ¨è¯„è®ºåŒºåˆ†äº«ä½ çš„çˆ¬è™«å¼€å‘ç»éªŒï¼Œæˆ–è€…æå‡ºæŠ€æœ¯é—®é¢˜ï¼Œæˆ‘ä¼šè®¤çœŸå›å¤æ¯ä¸€æ¡è¯„è®ºï¼

---

**æ ‡ç­¾**ï¼š#ç½‘ç»œçˆ¬è™« #Python #Scrapy #äººå·¥æ™ºèƒ½ #æ•°æ®é‡‡é›† #å†…å®¹æ¸…æ´— #Qoder #AIç¼–ç¨‹