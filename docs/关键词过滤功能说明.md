# 网页爬虫关键词过滤功能

## 功能概述

新增了智能关键词过滤功能，专门用于抓取与**矿山、自然资源、地质**相关的网页内容。这个功能可以大大提高抓取效率，减少无关内容的干扰。

## 特性

### ✅ 智能内容过滤
- **多层次检查**: 分析页面标题、meta信息、标题标签(h1-h6)和正文内容
- **权重评分**: 不同部分的关键词有不同权重
  - 页面标题: 权重 ×5
  - Meta信息: 权重 ×3  
  - 标题标签: 权重 ×2
  - 正文内容: 权重 ×1
- **判断标准**: 至少匹配2个关键词或总权重分数≥5分

### ✅ URL预过滤
- 在发起HTTP请求前就过滤掉明显不相关的URL
- 支持中英文关键词检查
- 优先保留政府机构(.gov)、组织(.org)、教育(.edu)网站

### ✅ 丰富的关键词库
包含93个相关关键词，涵盖：

#### 🏔️ 矿山相关 (22个)
- 基础词汇: 矿山、矿业、矿产、采矿、矿井、矿物、矿藏、开采、矿工、矿权
- 具体类型: 煤矿、金矿、铁矿、铜矿、铝矿、锌矿、石油、天然气、页岩气
- 技术流程: 露天开采、地下开采、选矿、冶炼、矿物加工、矿山安全、矿山环保

#### 🌍 自然资源相关 (15个)  
- 管理概念: 自然资源、国土资源、资源管理、资源开发、资源保护、资源配置
- 具体类型: 土地资源、水资源、森林资源、海洋资源、生态资源、能源
- 技术方法: 可再生能源、不可再生资源、资源勘探、资源评估、资源规划

#### 🗻 地质相关 (38个)
- 基础学科: 地质、地质勘探、地质调查、地质环境、地质灾害、地质工程
- 专业分支: 水文地质、工程地质、环境地质、海洋地质、构造地质、沉积地质
- 地质要素: 岩石、岩层、地层、断层、褶皱、地壳、地幔、板块构造
- 地质现象: 地震、火山、滑坡、泥石流、地面沉降、岩溶、喀斯特
- 技术方法: 钻探、物探、化探、遥感、测绘、地形测量、GIS、遥感影像

#### 🏛️ 相关机构和术语 (18个)
- 政府部门: 国土资源部、自然资源部、地质调查局
- 专业机构: 矿产资源、地质公园、地质博物馆、勘察设计、地质勘察
- 工程概念: 岩土工程、地基基础、环境影响评价、水土保持、生态修复
- 现代概念: 绿色矿山、智慧矿山

## 使用方法

### 基本用法

```bash
# 1. 启用关键词过滤 (默认模式)
python spider.py https://mnr.gov.cn
# 只抓取与矿山、自然资源、地质相关的页面

# 2. 禁用关键词过滤
python spider.py https://example.com --no-filter
# 抓取所有类型的页面

# 3. 随机抓取 + 关键词过滤
python spider.py --random
# 从数据库随机选择URL，并应用关键词过滤

# 4. 深度爬取相关网站
python spider.py https://mnr.gov.cn --depth 3 --delay 1
# 深度抓取自然资源部网站的相关内容
```

### 参数说明

| 参数 | 简写 | 默认值 | 说明 |
|------|------|--------|------|
| `--no-filter` | - | False | 禁用关键词过滤 |
| `--keyword-filter` | - | True | 启用关键词过滤(默认) |
| `--depth` | `-d` | 2 | 最大抓取深度 |
| `--delay` | - | 2 | 请求延迟秒数 |
| `--concurrent` | `-c` | 4 | 并发请求数 |

## 推荐抓取目标

### 🏛️ 政府机构
- **国家自然资源部**: https://mnr.gov.cn
- **中国地质调查局**: https://www.cgs.gov.cn  
- **各省自然资源厅**: 如 https://zrzy.jiangsu.gov.cn (江苏)

### 🏫 研究机构
- 地质类科研院所
- 矿业大学官网
- 地质博物馆网站

### 🏢 行业网站
- 大型矿业公司官网
- 地质勘探公司
- 自然资源行业协会

## 性能优化

### ✅ 效率提升
- **减少无效请求**: URL预过滤避免抓取明显不相关的页面
- **节省存储空间**: 只保存相关内容，减少垃圾数据
- **提高成功率**: 专注目标领域，相关内容占比更高

### ✅ 资源节约
- **带宽节省**: 避免下载大量无关页面
- **时间节省**: 快速跳过不相关内容
- **存储优化**: 减少无用HTML文件的存储

## 技术实现

### 内容相关性检查算法

```python
def is_content_relevant(self, html_content, url):
    # 1. 提取页面文本内容
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # 2. 获取不同权重的文本
    title_text = extract_title(soup) * 5      # 标题权重5倍
    meta_text = extract_meta(soup) * 3        # Meta权重3倍  
    heading_text = extract_headings(soup) * 2 # 标题标签权重2倍
    page_text = extract_text(soup)            # 正文权重1倍
    
    # 3. 权重计算
    weighted_content = title_text + meta_text + heading_text + page_text
    
    # 4. 关键词匹配
    matched_keywords = []
    keyword_count = 0
    for keyword in target_keywords:
        if keyword in weighted_content:
            matched_keywords.append(keyword)
            keyword_count += weighted_content.count(keyword)
    
    # 5. 判断标准
    return len(matched_keywords) >= 2 or keyword_count >= 5
```

### URL预过滤机制

```python
def is_url_potentially_relevant(self, url):
    # 1. 检查URL中的关键词
    url_keywords = ['矿', '地质', '资源', 'mining', 'geology', 'resource']
    
    # 2. 检查政府/机构域名
    institutional_domains = ['.gov.', '.org.', '.edu.']
    
    # 3. 综合判断
    return any(keyword in url.lower() for keyword in url_keywords) or \
           any(domain in url.lower() for domain in institutional_domains)
```

## 注意事项

### ⚠️ 潜在限制
- **误过滤风险**: 可能会过滤掉一些相关但关键词不明显的页面
- **语言支持**: 主要针对中文内容优化，英文有基本支持
- **上下文理解**: 基于关键词匹配，无法理解复杂的语义关系

### 💡 使用建议
- **首次使用**: 建议先用默认设置测试效果
- **特殊需求**: 如需更全面抓取，使用 `--no-filter` 禁用过滤
- **效果监控**: 定期检查 `--stats` 了解过滤效果
- **灵活调整**: 根据实际需求选择是否启用过滤

## 示例场景

### 场景1: 政府网站深度抓取
```bash
python spider.py https://mnr.gov.cn --depth 3 --delay 1
```
适用于: 抓取自然资源部的所有相关政策、公告、数据

### 场景2: 多网站并行抓取  
```bash
# 先添加多个起始URL
python spider.py https://mnr.gov.cn --depth 1
python spider.py https://www.cgs.gov.cn --depth 1  
# 然后随机继续
python spider.py --random --depth 2
```
适用于: 从多个相关网站收集信息

### 场景3: 无过滤全量抓取
```bash  
python spider.py https://example.com --no-filter --depth 2
```
适用于: 需要抓取网站的所有内容进行分析

通过这个关键词过滤功能，您可以更精准地抓取与矿山、自然资源、地质相关的网页内容，大大提高数据收集的效率和质量。