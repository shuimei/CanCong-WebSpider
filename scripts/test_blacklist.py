#!/usr/bin/env python3
"""
æµ‹è¯•å±è”½è§„åˆ™åŠŸèƒ½
éªŒè¯URLå±è”½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from scripts.url_collector import UrlCollector


def test_blacklist_function():
    """æµ‹è¯•å±è”½è§„åˆ™åŠŸèƒ½"""
    print("æµ‹è¯•å±è”½è§„åˆ™åŠŸèƒ½")
    print("=" * 50)
    
    # åˆ›å»ºå¸¦å±è”½åˆ—è¡¨çš„URLæ”¶é›†å™¨
    collector = UrlCollector(
        blacklist_file="blacklist.txt"
    )
    
    # æµ‹è¯•å±è”½è§„åˆ™åŠ è½½
    print(f"åŠ è½½çš„å±è”½è§„åˆ™æ•°é‡: {len(collector.blacklist_patterns)}")
    print("å‰10ä¸ªå±è”½è§„åˆ™:")
    for i, pattern in enumerate(list(collector.blacklist_patterns)[:10]):
        print(f"  {i+1}. {pattern}")
    
    # æµ‹è¯•URLå±è”½æ£€æŸ¥
    test_urls = [
        "https://www.facebook.com",
        "https://www.google.com",
        "https://www.taobao.com",
        "https://www.cgs.gov.cn",
        "https://example.com/download/file.zip",
        "https://news.sina.com.cn",
        "https://example.com/page"
    ]
    
    print("\nURLå±è”½æ£€æŸ¥æµ‹è¯•:")
    for url in test_urls:
        is_blacklisted = collector.is_blacklisted(url)
        status = "ğŸš« å±è”½" if is_blacklisted else "âœ… å…è®¸"
        print(f"  {status} {url}")
    
    # æµ‹è¯•should_crawl_urlæ–¹æ³•
    print("\nURLæŠ“å–æ£€æŸ¥æµ‹è¯•:")
    for url in test_urls:
        should_crawl = collector.should_crawl_url(url)
        status = "âœ… æŠ“å–" if should_crawl else "ğŸš« ä¸æŠ“å–"
        print(f"  {status} {url}")


def test_with_different_blacklist():
    """æµ‹è¯•ä½¿ç”¨ä¸åŒçš„å±è”½åˆ—è¡¨"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•ä½¿ç”¨ç©ºå±è”½åˆ—è¡¨")
    
    # åˆ›å»ºä¸ä½¿ç”¨å±è”½åˆ—è¡¨çš„URLæ”¶é›†å™¨
    collector_no_blacklist = UrlCollector()
    
    test_urls = [
        "https://www.facebook.com",
        "https://www.google.com",
        "https://www.taobao.com"
    ]
    
    print("ä¸ä½¿ç”¨å±è”½åˆ—è¡¨æ—¶çš„æ£€æŸ¥ç»“æœ:")
    for url in test_urls:
        should_crawl = collector_no_blacklist.should_crawl_url(url)
        status = "âœ… æŠ“å–" if should_crawl else "ğŸš« ä¸æŠ“å–"
        print(f"  {status} {url}")


def main():
    """ä¸»å‡½æ•°"""
    test_blacklist_function()
    test_with_different_blacklist()
    
    print("\n" + "=" * 50)
    print("ä½¿ç”¨æ–¹æ³•:")
    print("1. ä½¿ç”¨é»˜è®¤å±è”½åˆ—è¡¨:")
    print("   python scripts/url_collector.py --blacklist blacklist.txt --url https://example.com")
    print("")
    print("2. ä½¿ç”¨è‡ªå®šä¹‰å±è”½åˆ—è¡¨:")
    print("   python scripts/url_collector.py --blacklist my_blacklist.txt --from-database")
    print("")
    print("3. éšæœºURLæ”¶é›†å™¨ä½¿ç”¨å±è”½åˆ—è¡¨:")
    print("   python scripts/random_url_collector.py --blacklist blacklist.txt")


if __name__ == '__main__':
    main()