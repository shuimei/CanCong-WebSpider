#!/usr/bin/env python3
"""
æ™ºèƒ½çˆ¬è™«è°ƒåº¦è„šæœ¬
å¾ªç¯éšæœºé€‰æ‹©æœªæŠ“å–çš„URLï¼Œå¯åŠ¨çˆ¬è™«ä»»åŠ¡ï¼Œç›´åˆ°æ‰€æœ‰URLéƒ½è¢«æŠ“å–å®Œæˆ
"""

import os
import sys
import time
import signal
import random
import sqlite3
import subprocess
import threading
import queue
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed


class SpiderScheduler:
    """çˆ¬è™«è°ƒåº¦å™¨"""
    
    def __init__(self, project_dir=None, max_concurrent=2, delay_between_tasks=10):
        """
        åˆå§‹åŒ–è°ƒåº¦å™¨
        
        Args:
            project_dir: é¡¹ç›®æ ¹ç›®å½•
            max_concurrent: æœ€å¤§å¹¶å‘è¿›ç¨‹æ•°ï¼ˆé»˜è®¤2ï¼‰
            delay_between_tasks: ä»»åŠ¡ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
        """
        self.project_dir = Path(project_dir) if project_dir else Path(__file__).parent.parent
        self.db_path = self.project_dir / 'spider_urls.db'
        self.max_concurrent = max_concurrent
        self.delay_between_tasks = delay_between_tasks
        self.running = False
        self.active_processes = {}  # å­˜å‚¨æ´»è·ƒè¿›ç¨‹ {thread_id: (process, url, start_time)}
        self.process_lock = threading.Lock()  # çº¿ç¨‹å®‰å…¨é”
        self.url_queue = queue.Queue()  # URLé˜Ÿåˆ—
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_urls': 0,
            'completed_urls': 0,
            'failed_urls': 0,
            'pending_urls': 0,
            'current_tasks': {},  # {thread_id: url}
            'start_time': None,
            'tasks_completed': 0,
            'active_workers': 0
        }
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
        
        print(f"çˆ¬è™«è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"é¡¹ç›®ç›®å½•: {self.project_dir}")
        print(f"æ•°æ®åº“è·¯å¾„: {self.db_path}")
        print(f"æœ€å¤§å¹¶å‘æ•°: {self.max_concurrent}")
        print(f"ä»»åŠ¡é—´å»¶è¿Ÿ: {self.delay_between_tasks}ç§’")
    
    def signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨ï¼Œç”¨äºä¼˜é›…é€€å‡º"""
        print(f"\næ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨åœæ­¢è°ƒåº¦å™¨...")
        self.stop()
    
    def get_database_stats(self):
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        if not self.db_path.exists():
            return None
            
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ€»URLæ•°é‡
            cursor.execute("SELECT COUNT(*) FROM urls")
            total = cursor.fetchone()[0]
            
            # å·²å®Œæˆæ•°é‡
            cursor.execute("SELECT COUNT(*) FROM urls WHERE status = 'completed'")
            completed = cursor.fetchone()[0]
            
            # å¤±è´¥æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM urls WHERE status = 'failed'")
            failed = cursor.fetchone()[0]
            
            # å¾…æŠ“å–æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM urls WHERE status = 'pending'")
            pending = cursor.fetchone()[0]
            
            # æ­£åœ¨å¤„ç†æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM urls WHERE status = 'crawling'")
            crawling = cursor.fetchone()[0]
            
            conn.close()
            
            return {
                'total': total,
                'completed': completed,
                'failed': failed,
                'pending': pending,
                'crawling': crawling
            }
            
        except Exception as e:
            print(f"è·å–æ•°æ®åº“ç»Ÿè®¡å¤±è´¥: {e}")
            return None
    
    def get_multiple_random_pending_urls(self, count):
        """è·å–å¤šä¸ªéšæœºå¾…æŠ“å–çš„URL"""
        if not self.db_path.exists():
            print("æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
            return []
            
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # éšæœºè·å–å¤šä¸ªå¾…æŠ“å–çš„URL
            cursor.execute("""
                SELECT url FROM urls 
                WHERE status = 'pending' 
                ORDER BY RANDOM() 
                LIMIT ?
            """, (count,))
            
            results = cursor.fetchall()
            conn.close()
            
            return [result[0] for result in results]
            
        except Exception as e:
            print(f"è·å–éšæœºURLå¤±è´¥: {e}")
            return []

    def get_random_pending_url(self):
        """éšæœºè·å–ä¸€ä¸ªå¾…æŠ“å–çš„URL"""
        if not self.db_path.exists():
            print("æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
            return None
            
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # éšæœºè·å–ä¸€ä¸ªå¾…æŠ“å–çš„URL
            cursor.execute("""
                SELECT url FROM urls 
                WHERE status = 'pending' 
                ORDER BY RANDOM() 
                LIMIT 1
            """)
            
            result = cursor.fetchone()
            conn.close()
            
            return result[0] if result else None
            
        except Exception as e:
            print(f"è·å–éšæœºURLå¤±è´¥: {e}")
            return None
    
    def mark_url_crawling(self, url):
        """æ ‡è®°URLä¸ºæ­£åœ¨æŠ“å–çŠ¶æ€"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¡¨ç»“æ„ï¼Œçœ‹æ˜¯å¦æœ‰last_crawl_timeåˆ—
            cursor.execute("PRAGMA table_info(urls)")
            columns = [column[1] for column in cursor.fetchall()]
            
            if 'last_crawl_time' in columns:
                # å¦‚æœæœ‰last_crawl_timeåˆ—ï¼Œæ›´æ–°æ—¶é—´
                cursor.execute("""
                    UPDATE urls 
                    SET status = 'crawling', last_crawl_time = ? 
                    WHERE url = ?
                """, (datetime.now().isoformat(), url))
            else:
                # å¦‚æœæ²¡æœ‰last_crawl_timeåˆ—ï¼Œåªæ›´æ–°çŠ¶æ€
                cursor.execute("""
                    UPDATE urls 
                    SET status = 'crawling' 
                    WHERE url = ?
                """, (url,))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"æ ‡è®°URLçŠ¶æ€å¤±è´¥: {e}")
    
    def run_spider_for_url(self, url, worker_id=None):
        """ä¸ºæŒ‡å®šURLè¿è¡Œçˆ¬è™«"""
        worker_info = f"[Worker-{worker_id}]" if worker_id else ""
        try:
            print(f"\n{'='*60}")
            print(f"{worker_info} å¼€å§‹æŠ“å–: {url}")
            print(f"{worker_info} æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"{'='*60}")
            
            # æ ‡è®°URLä¸ºæ­£åœ¨æŠ“å–
            self.mark_url_crawling(url)
            
            # æ›´æ–°å½“å‰ä»»åŠ¡ç»Ÿè®¡
            with self.process_lock:
                if worker_id:
                    self.stats['current_tasks'][worker_id] = url
                    self.stats['active_workers'] = len(self.stats['current_tasks'])
            
            # æ„å»ºçˆ¬è™«å‘½ä»¤
            spider_script = self.project_dir / 'spider.py'
            if not spider_script.exists():
                raise FileNotFoundError(f"çˆ¬è™«è„šæœ¬ä¸å­˜åœ¨: {spider_script}")
            
            # è¿è¡Œçˆ¬è™«å‘½ä»¤
            cmd = [
                sys.executable,
                str(spider_script),
                url,
                '--depth', '2'  # é»˜è®¤æ·±åº¦ä¸º2
            ]
            
            print(f"{worker_info} æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            # å¯åŠ¨å­è¿›ç¨‹
            process = subprocess.Popen(
                cmd,
                cwd=str(self.project_dir),
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            # è®°å½•æ´»è·ƒè¿›ç¨‹
            with self.process_lock:
                if worker_id:
                    self.active_processes[worker_id] = (process, url, datetime.now())
            
            # å®æ—¶è¾“å‡ºçˆ¬è™«æ—¥å¿—ï¼ˆä½†ä¸é˜»å¡å…¶ä»–workerï¼‰
            output_lines = []
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    line = f"{worker_info} {output.strip()}"
                    print(line)
                    output_lines.append(line)
            
            # ç­‰å¾…è¿›ç¨‹å®Œæˆ
            return_code = process.wait()
            
            # æ¸…é™¤æ´»è·ƒè¿›ç¨‹è®°å½•
            with self.process_lock:
                if worker_id and worker_id in self.active_processes:
                    del self.active_processes[worker_id]
                if worker_id and worker_id in self.stats['current_tasks']:
                    del self.stats['current_tasks'][worker_id]
                self.stats['active_workers'] = len(self.stats['current_tasks'])
            
            if return_code == 0:
                print(f"\nâœ… {worker_info} æŠ“å–å®Œæˆ: {url}")
                with self.process_lock:
                    self.stats['tasks_completed'] += 1
                return True
            else:
                print(f"\nâŒ {worker_info} æŠ“å–å¤±è´¥: {url} (è¿”å›ç : {return_code})")
                return False
                
        except KeyboardInterrupt:
            print(f"\nâ¸ï¸  {worker_info} ç”¨æˆ·ä¸­æ–­æŠ“å–: {url}")
            if 'process' in locals():
                process.terminate()
                process.wait()
            return False
            
        except Exception as e:
            print(f"\nğŸ’¥ {worker_info} æŠ“å–å¼‚å¸¸: {url} - {e}")
            return False
        finally:
            # ç¡®ä¿æ¸…é™¤ç»Ÿè®¡ä¿¡æ¯
            with self.process_lock:
                if worker_id and worker_id in self.active_processes:
                    del self.active_processes[worker_id]
                if worker_id and worker_id in self.stats['current_tasks']:
                    del self.stats['current_tasks'][worker_id]
                self.stats['active_workers'] = len(self.stats['current_tasks'])
    
    def clean_stale_crawling_status(self):
        """æ¸…ç†é•¿æ—¶é—´å¤„äºcrawlingçŠ¶æ€çš„URLï¼ˆå¯èƒ½æ˜¯å¼‚å¸¸é€€å‡ºç•™ä¸‹çš„ï¼‰"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¡¨ç»“æ„ï¼Œçœ‹æ˜¯å¦æœ‰last_crawl_timeåˆ—
            cursor.execute("PRAGMA table_info(urls)")
            columns = [column[1] for column in cursor.fetchall()]
            
            if 'last_crawl_time' in columns:
                # å¦‚æœæœ‰last_crawl_timeåˆ—ï¼Œä½¿ç”¨æ—¶é—´æ¡ä»¶
                cursor.execute("""
                    UPDATE urls 
                    SET status = 'pending' 
                    WHERE status = 'crawling' 
                    AND datetime(last_crawl_time) < datetime('now', '-1 hour')
                """)
            else:
                # å¦‚æœæ²¡æœ‰last_crawl_timeåˆ—ï¼ŒåªæŒ‰çŠ¶æ€æ¸…ç†
                cursor.execute("""
                    UPDATE urls 
                    SET status = 'pending' 
                    WHERE status = 'crawling'
                """)
            
            affected = cursor.rowcount
            if affected > 0:
                print(f"é‡ç½®äº† {affected} ä¸ªé•¿æ—¶é—´æœªå®Œæˆçš„æŠ“å–ä»»åŠ¡")
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"æ¸…ç†å¼‚å¸¸çŠ¶æ€å¤±è´¥: {e}")
    
    def print_progress(self):
        """æ‰“å°å½“å‰è¿›åº¦"""
        stats = self.get_database_stats()
        if stats:
            self.stats.update(stats)
            
            total = stats['total']
            completed = stats['completed']
            failed = stats['failed']
            pending = stats['pending']
            crawling = stats['crawling']
            
            if total > 0:
                progress = (completed / total) * 100
                print(f"\nğŸ“Š å½“å‰è¿›åº¦:")
                print(f"  æ€»URLæ•°: {total}")
                print(f"  å·²å®Œæˆ: {completed} ({progress:.1f}%)")
                print(f"  å¾…æŠ“å–: {pending}")
                print(f"  æŠ“å–ä¸­: {crawling}")
                print(f"  å¤±è´¥: {failed}")
                print(f"  å½“å‰æ´»è·ƒWorker: {self.stats['active_workers']}")
                print(f"  æœ¬æ¬¡ä»»åŠ¡æ•°: {self.stats['tasks_completed']}")
                
                # æ˜¾ç¤ºæ´»è·ƒä»»åŠ¡
                with self.process_lock:
                    if self.stats['current_tasks']:
                        print(f"  æ´»è·ƒä»»åŠ¡:")
                        for worker_id, url in self.stats['current_tasks'].items():
                            print(f"    Worker-{worker_id}: {url[:50]}...")
                
                if self.stats['start_time']:
                    elapsed = (datetime.now() - self.stats['start_time']).total_seconds()
                    if elapsed > 0:
                        speed = self.stats['tasks_completed'] / (elapsed / 3600)  # ä»»åŠ¡/å°æ—¶
                        print(f"  è¿è¡Œæ—¶é—´: {elapsed/60:.1f}åˆ†é’Ÿ")
                        print(f"  å¹³å‡é€Ÿåº¦: {speed:.1f}ä»»åŠ¡/å°æ—¶")
    
    def start(self):
        """å¼€å§‹è°ƒåº¦"""
        print(f"\nğŸš€ å¯åŠ¨çˆ¬è™«è°ƒåº¦å™¨ (æœ€å¤§å¹¶å‘: {self.max_concurrent})")
        print("æŒ‰ Ctrl+C å¯ä»¥éšæ—¶åœæ­¢")
        
        # æ£€æŸ¥æ•°æ®åº“
        if not self.db_path.exists():
            print("âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«æ·»åŠ ä¸€äº›URL")
            return
        
        # æ¸…ç†å¼‚å¸¸çŠ¶æ€
        self.clean_stale_crawling_status()
        
        # è·å–åˆå§‹ç»Ÿè®¡
        initial_stats = self.get_database_stats()
        if not initial_stats or initial_stats['total'] == 0:
            print("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰URLï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«æ·»åŠ ä¸€äº›URL")
            return
        
        if initial_stats['pending'] == 0:
            print("âœ… æ‰€æœ‰URLéƒ½å·²å¤„ç†å®Œæˆï¼")
            return
        
        print(f"ğŸ“‹ æ‰¾åˆ° {initial_stats['pending']} ä¸ªå¾…æŠ“å–URLï¼Œå¼€å§‹è°ƒåº¦...")
        
        self.running = True
        self.stats['start_time'] = datetime.now()
        
        try:
            # ä½¿ç”¨çº¿ç¨‹æ± ç®¡ç†å¤šä¸ªworker
            with ThreadPoolExecutor(max_workers=self.max_concurrent) as executor:
                active_futures = {}
                
                while self.running:
                    try:
                        # è·å–å½“å‰ç»Ÿè®¡
                        stats = self.get_database_stats()
                        if not stats:
                            print("âŒ æ— æ³•è·å–æ•°æ®åº“ç»Ÿè®¡ï¼Œåœæ­¢è°ƒåº¦")
                            break
                        
                        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¾…æŠ“å–çš„URL
                        if stats['pending'] == 0 and len(active_futures) == 0:
                            print("\nğŸ‰ æ‰€æœ‰URLéƒ½å·²æŠ“å–å®Œæˆï¼")
                            break
                        
                        # æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡
                        completed_futures = []
                        try:
                            # ä½¿ç”¨éé˜»å¡æ–¹å¼æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡
                            for future in list(active_futures.keys()):
                                if future.done():
                                    try:
                                        worker_id = active_futures[future]
                                        result = future.result(timeout=0.1)  # å¾ˆçŸ­çš„è¶…æ—¶ï¼Œåªæ˜¯ä¸ºäº†è·å–ç»“æœ
                                        completed_futures.append(future)
                                        print(f"\nğŸ Worker-{worker_id} ä»»åŠ¡å®Œæˆ")
                                    except Exception as e:
                                        worker_id = active_futures[future]
                                        print(f"\nâš ï¸ Worker-{worker_id} ä»»åŠ¡å¼‚å¸¸: {e}")
                                        completed_futures.append(future)
                        except Exception as e:
                            print(f"æ£€æŸ¥ä»»åŠ¡çŠ¶æ€æ—¶å‡ºé”™: {e}")
                        
                        # æ¸…ç†å·²å®Œæˆçš„future
                        for future in completed_futures:
                            if future in active_futures:
                                del active_futures[future]
                        
                        # å¯åŠ¨æ–°çš„workerä»»åŠ¡
                        available_slots = self.max_concurrent - len(active_futures)
                        if available_slots > 0 and stats['pending'] > 0:
                            # è·å–å¤šä¸ªå¾…æŠ“å–URL
                            urls = self.get_multiple_random_pending_urls(available_slots)
                            
                            for i, url in enumerate(urls):
                                if not self.running:
                                    break
                                    
                                worker_id = len(active_futures) + i + 1
                                future = executor.submit(self.run_spider_for_url, url, worker_id)
                                active_futures[future] = worker_id
                                print(f"\nğŸš€ å¯åŠ¨ Worker-{worker_id}: {url}")
                        
                        # ç­‰å¾…ç­–ç•¥
                        if len(active_futures) > 0:
                            time.sleep(2)  # ç­‰å¾…ä¸€ä¸‹å†æ£€æŸ¥
                        else:
                            # æ²¡æœ‰æ´»è·ƒä»»åŠ¡æ—¶ï¼Œç­‰å¾…ä¸€ä¸‹å†æŸ¥æ‰¾æ–°URL
                            if stats['pending'] > 0:
                                time.sleep(self.delay_between_tasks)
                        
                        # å®šæœŸæ˜¾ç¤ºè¿›åº¦
                        if hasattr(self, '_last_progress_time'):
                            if (datetime.now() - self._last_progress_time).total_seconds() > 30:
                                self.print_progress()
                                self._last_progress_time = datetime.now()
                        else:
                            self.print_progress()
                            self._last_progress_time = datetime.now()
                            
                    except Exception as e:
                        print(f"è°ƒåº¦å¾ªç¯ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                        import traceback
                        traceback.print_exc()
                        # ç­‰å¾…ä¸€ä¸‹å†ç»§ç»­
                        time.sleep(2)
                
                # ç­‰å¾…æ‰€æœ‰æ´»è·ƒä»»åŠ¡å®Œæˆ
                if active_futures:
                    print(f"\nâ³ ç­‰å¾… {len(active_futures)} ä¸ªæ´»è·ƒä»»åŠ¡å®Œæˆ...")
                    # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼ç­‰å¾…ä»»åŠ¡å®Œæˆ
                    remaining_futures = list(active_futures.keys())
                    while remaining_futures:
                        completed_in_batch = []
                        for future in remaining_futures:
                            if future.done():
                                try:
                                    worker_id = active_futures[future]
                                    result = future.result()
                                    print(f"Worker-{worker_id} æœ€ç»ˆå®Œæˆ")
                                except Exception as e:
                                    worker_id = active_futures[future]
                                    print(f"Worker-{worker_id} æœ€ç»ˆå¼‚å¸¸: {e}")
                                completed_in_batch.append(future)
                        
                        # ç§»é™¤å·²å®Œæˆçš„ä»»åŠ¡
                        for future in completed_in_batch:
                            remaining_futures.remove(future)
                        
                        # å¦‚æœè¿˜æœ‰æœªå®Œæˆçš„ä»»åŠ¡ï¼Œç­‰å¾…ä¸€ä¸‹
                        if remaining_futures:
                            time.sleep(1)
                            
        except KeyboardInterrupt:
            print("\nâ¸ï¸ ç”¨æˆ·ä¸­æ–­è°ƒåº¦")
        except Exception as e:
            print(f"\nğŸ’¥ è°ƒåº¦å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.running = False
            
            # æœ€ç»ˆç»Ÿè®¡
            final_stats = self.get_database_stats()
            if final_stats:
                print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
                print(f"  æ€»URLæ•°: {final_stats['total']}")
                print(f"  å·²å®Œæˆ: {final_stats['completed']}")
                print(f"  å¾…æŠ“å–: {final_stats['pending']}")
                print(f"  å¤±è´¥: {final_stats['failed']}")
                print(f"  æœ¬æ¬¡å®Œæˆä»»åŠ¡æ•°: {self.stats['tasks_completed']}")
                
                if self.stats['start_time']:
                    total_time = (datetime.now() - self.stats['start_time']).total_seconds()
                    print(f"  æ€»è¿è¡Œæ—¶é—´: {total_time/60:.1f}åˆ†é’Ÿ")
                    if total_time > 0:
                        speed = self.stats['tasks_completed'] / (total_time / 3600)
                        print(f"  å¹³å‡é€Ÿåº¦: {speed:.1f}ä»»åŠ¡/å°æ—¶")
            
            print("\nğŸ‘‹ è°ƒåº¦å™¨å·²åœæ­¢")
    
    def stop(self):
        """åœæ­¢è°ƒåº¦"""
        self.running = False
        
        # ç»ˆæ­¢æ‰€æœ‰æ´»è·ƒè¿›ç¨‹
        with self.process_lock:
            if self.active_processes:
                print(f"æ­£åœ¨ç»ˆæ­¢ {len(self.active_processes)} ä¸ªæ´»è·ƒçˆ¬è™«è¿›ç¨‹...")
                
                for worker_id, (process, url, start_time) in self.active_processes.items():
                    try:
                        print(f"ç»ˆæ­¢ Worker-{worker_id}: {url}")
                        process.terminate()
                    except Exception as e:
                        print(f"ç»ˆæ­¢ Worker-{worker_id} å¤±è´¥: {e}")
                
                # ç­‰å¾…è¿›ç¨‹ç»ˆæ­¢
                for worker_id, (process, url, start_time) in self.active_processes.items():
                    try:
                        process.wait(timeout=10)
                        print(f"Worker-{worker_id} å·²ç»ˆæ­¢")
                    except subprocess.TimeoutExpired:
                        print(f"å¼ºåˆ¶ç»ˆæ­¢ Worker-{worker_id}...")
                        process.kill()
                        process.wait()
                    except Exception as e:
                        print(f"Worker-{worker_id} ç»ˆæ­¢å¼‚å¸¸: {e}")
                
                self.active_processes.clear()


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='çˆ¬è™«æ™ºèƒ½è°ƒåº¦å™¨')
    parser.add_argument('--delay', '-d', type=int, default=10,
                       help='ä»»åŠ¡ä¹‹é—´çš„å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤10ç§’ï¼‰')
    parser.add_argument('--workers', '-w', type=int, default=2,
                       help='æœ€å¤§å¹¶å‘workeræ•°é‡ï¼ˆé»˜è®¤2ï¼‰')
    parser.add_argument('--project-dir', '-p', type=str,
                       help='é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ä¸ºè„šæœ¬æ‰€åœ¨ç›®å½•çš„ä¸Šçº§ï¼‰')
    parser.add_argument('--stats', '-s', action='store_true',
                       help='åªæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼Œä¸å¯åŠ¨è°ƒåº¦')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = SpiderScheduler(
        project_dir=args.project_dir,
        max_concurrent=args.workers,
        delay_between_tasks=args.delay
    )
    
    if args.stats:
        # åªæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        stats = scheduler.get_database_stats()
        if stats:
            print(f"  æ€»URLæ•°: {stats['total']}")
            print(f"  å·²å®Œæˆ: {stats['completed']}")
            print(f"  å¾…æŠ“å–: {stats['pending']}")
            print(f"  æŠ“å–ä¸­: {stats['crawling']}")
            print(f"  å¤±è´¥: {stats['failed']}")
        else:
            print("  æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯")
    else:
        # å¯åŠ¨è°ƒåº¦å™¨
        scheduler.start()


if __name__ == '__main__':
    main()